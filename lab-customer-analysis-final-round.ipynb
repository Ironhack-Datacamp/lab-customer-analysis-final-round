{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                           # panel data, handling dataframes\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/marketing-customer-analysis.csv')    # import csv file\n",
    "data.head()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape       # dataframe dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns     # columns headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=[e.lower().replace(' ', '_') for e in data.columns]   # lower and replace\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(memory_usage='deep')   # dataframe info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()     # missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['unnamed:_0', 'vehicle_type', 'customer'])   # drop useless columns (no info or nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()   # drop rows with nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.columns.tolist():         # know the unique values for each column\n",
    "    print(c, len(data[c].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original dtype: {}\\n'.format(data['effective_to_date'].dtype))   # object\n",
    "data['effective_to_date']=pd.to_datetime(data['effective_to_date'])   # datetime\n",
    "print('Meantime dtype: {}'.format(data['effective_to_date'].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--')\n",
    "print('Min date: {}'.format(data['effective_to_date'].min()))         # from January 1st..\n",
    "print('Max date: {}'.format(data['effective_to_date'].max()))         # to February 28th\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['effective_to_date']=data['effective_to_date'].apply(lambda x: x.toordinal())   # you can change the type to ordinal.\n",
    "\n",
    "print('New dtype: {}'.format(data['effective_to_date'].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=[col for col in data.columns if (data[col].dtype==object)]     # categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Categorical Features:', len(cat_cols))\n",
    "print('----------')\n",
    "for c in cat_cols:\n",
    "    print('Name: {}'.format(data[c].name))    # column name\n",
    "    print('Type: {}'.format(data[c].dtype))   # column type\n",
    "    print('Unique values: {}'.format(len(data[c].unique())))   # column unique values\n",
    "    print(data[c].unique())\n",
    "    print(((data[c].value_counts()/ sum(data[c].value_counts()))*100))   # percentage\n",
    "    print('\\n----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()     # stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=[c for c in data.columns if (data[c].dtype!='object') and (c!='Effective To Date')]   # numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                 # visualization library\n",
    "%matplotlib inline\n",
    "\n",
    "for c in cat_cols:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(data[c].unique(), data[c].value_counts())\n",
    "    plt.title(c)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns                           # visualization library, extends plt\n",
    "sns.set(style=\"white\")                          # style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    # numerical python, algebra library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=data.corr()      # compute the correlation matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.triu(np.ones_like(corr, dtype=np.bool))     # generate a mask for the upper triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax=plt.subplots(figsize=(11, 9))                 # set up the matplotlib figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap=sns.diverging_palette(220, 10, as_cmap=True)   # generate a custom diverging colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr, mask=mask, cmap=cmap,             # draw the heatmap with the mask and correct aspect ratio\n",
    "            vmax=.3, center=0, square=True,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all variables\n",
    "sns.pairplot(data[num_cols]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in num_cols:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.hist(data[c])\n",
    "    plt.title(c)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in num_cols:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.boxplot(data[c])\n",
    "    plt.title(c)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('response', data=data)\n",
    "plt.ylabel('Total number of Response')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot('response', hue='sales_channel', data=data)\n",
    "plt.ylabel('Response by Sales Channel')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y='total_claim_amount' , x='response', data=data)\n",
    "plt.ylabel('Response by Total Claim Amount')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y='income' , x='response', data=data)\n",
    "plt.ylabel('Response by Inncome')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. 3*IQR in a column\n",
    "\n",
    "q1=np.percentile(data['customer_lifetime_value'], 25)   # percentile 25\n",
    "q3=np.percentile(data['customer_lifetime_value'], 75)   # percentile 75\n",
    "\n",
    "iqr=q3-q1  # IQR\n",
    "\n",
    "upper=q3+3*iqr   # upper boundary\n",
    "lower=q1-3*iqr   # lower boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['customer_lifetime_value']<lower])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['customer_lifetime_value']>upper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data['effective_to_date']=MinMaxScaler().fit_transform(data['effective_to_date'].values.reshape(-1, 1))\n",
    "\n",
    "data['effective_to_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in num_cols[:-1]:   # we'll normalize all less the target column\n",
    "    data[c]=StandardScaler().fit_transform(data[c].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data=pd.get_dummies(data[cat_cols], drop_first=True)   # one hot encoding categorical variables\n",
    "\n",
    "one_hot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([data, one_hot_data], axis=1)   # concat dataframes\n",
    "data.drop(columns=cat_cols, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, split X-y (learning-target data)\n",
    "X=data.drop(columns=['total_claim_amount'])\n",
    "y=data['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split (4 sets)\n",
    "\n",
    "X_train, X_test, y_train, y_test=tts(X, y, test_size=0.2, random_state=42)  # random state fixed sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "linreg=LinReg()    # model\n",
    "linreg.fit(X_train, y_train)   # model train\n",
    "y_pred_linreg=linreg.predict(X_test)   # model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso       # L1\n",
    "from sklearn.linear_model import Ridge       # L2\n",
    "from sklearn.linear_model import ElasticNet  # L1+L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso L1\n",
    "\n",
    "lasso=Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lasso=lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge L2\n",
    "\n",
    "ridge=Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge=ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet L1+L2\n",
    "\n",
    "elastic=ElasticNet()\n",
    "elastic.fit(X_train, y_train)\n",
    "\n",
    "y_pred_elastic=elastic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "\n",
    "rfr=RFR()\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rfr=rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor as XGBR\n",
    "\n",
    "xgbr=XGBR()\n",
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgbr=xgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor as LGBMR\n",
    "\n",
    "lgbmr=LGBMR()\n",
    "lgbmr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgbmr=lgbmr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[linreg, lasso, ridge, elastic, rfr, xgbr, lgbmr]\n",
    "model_names=['linreg', 'lasso', 'ridge', 'elastic', 'rfr', 'xgbr', 'lgbmr']\n",
    "preds=[y_pred_linreg, y_pred_lasso, y_pred_ridge, y_pred_elastic, y_pred_rfr, y_pred_xgbr, y_pred_lgbmr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "\n",
    "    train_score=models[i].score(X_train, y_train) #R2\n",
    "    test_score=models[i].score(X_test, y_test)\n",
    "\n",
    "    print ('Model: {}, train R2: {} -- test R2: {}'.format(model_names[i], train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "for i in range(len(models)):\n",
    "\n",
    "    train_mse=mse(models[i].predict(X_train), y_train) #MSE\n",
    "    test_mse=mse(preds[i], y_test)\n",
    "\n",
    "    print ('Model: {}, train MSE: {} -- test MSE: {}'.format(model_names[i], train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "\n",
    "    train_rmse=mse(models[i].predict(X_train), y_train)**0.5 #RMSE\n",
    "    test_rmse=mse(preds[i], y_test)**0.5\n",
    "\n",
    "    print ('Model: {}, train RMSE: {} -- test RMSE: {}'.format(model_names[i], train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "for i in range(len(models)):\n",
    "    train_mae=mae(models[i].predict(X_train), y_train) #MAE\n",
    "    test_mae=mae(preds[i], y_test)\n",
    "\n",
    "    print ('Model: {}, train MAE: {} -- test MAE: {}'.format(model_names[i], train_mae, test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07 - Reporting\n",
    "\n",
    "- Present results.\n",
    "\n",
    "**Data Level**\n",
    "\n",
    "- Drop Nan values because they are, in fact, duplicates.\n",
    "- Do not drop outliers because they are just a few.\n",
    "\n",
    "**Problem Level**\n",
    "\n",
    "- Total claim amount has a great variance.\n",
    "- We can predict the total claim amount with a 25% of error, even when R2 is high.\n",
    "- We need to determinate which are the significative variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
